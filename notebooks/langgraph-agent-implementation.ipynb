{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangGraph Agent Implementation",
    "",
    "This notebook demonstrates how to build dynamic, state-aware AI agents using LangGraph's graph-based workflow system. LangGraph extends LangChain with stateful, cyclical, and graph-based workflows, making it possible to create more sophisticated AI agents.",
    "",
    "## Learning Objectives",
    "",
    "- Understand LangGraph's approach to stateful agent architecture",
    "- Build a graph-based workflow with different execution paths",
    "- Implement proper state management between workflow steps",
    "- Integrate tool usage for expanded agent capabilities",
    "- Handle errors and implement fallback mechanisms",
    "- Visualize agent execution paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup",
    "",
    "Let's install the necessary packages to work with LangGraph and LangChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages",
    "!pip install langchain langgraph openai tavily-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List, Annotated, Dict, Any",
    "import operator",
    "from langchain_openai import ChatOpenAI",
    "from langchain.prompts import ChatPromptTemplate",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage",
    "from langgraph.graph import StateGraph, END",
    "from langgraph.checkpoint.memory import MemoryCheckpointExecutor",
    "import os",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup",
    "",
    "First, we'll set up our environment by configuring our API keys for OpenAI and any other services we'll use. For security, it's best to use environment variables for API keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your OpenAI API key here or use environment variable",
    "# Note: In a production environment, never hardcode API keys",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-api-key-here\"  # Uncomment and replace with your key",
    "# os.environ[\"TAVILY_API_KEY\"] = \"your-tavily-api-key-here\"  # For search tool",
    "",
    "# Initialize LLM with a smaller model to reduce costs during development",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Agent State",
    "",
    "We'll define the state that our agent will maintain throughout its execution. This state will be updated as the agent moves through different nodes in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our agent's state using a TypedDict for type safety",
    "class AgentState(TypedDict):",
    "    # Messages exchanged so far",
    "    messages: List[Any]  # Can be HumanMessage, AIMessage, etc.",
    "    # Store intermediate steps for reasoning",
    "    intermediate_steps: List[Dict[str, Any]]",
    "    # Current task the agent is working on",
    "    current_task: str",
    "    # Whether we need to use tools",
    "    use_tools: bool",
    "    # Counter for retry attempts",
    "    retry_count: int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Tools",
    "",
    "Let's create some tools that our agent can use to accomplish tasks. We'll implement a calculator tool and a simple search tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple calculator tool",
    "def calculator(expression: str) -> str:",
    "    """Evaluate a mathematical expression."""",
    "    try: